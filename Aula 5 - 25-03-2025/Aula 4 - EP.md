# Engenharia de Prompt: Uma Abordagem Atualizada com Exemplos Pr√°ticos para Sala de Aula ü§ñ‚ú®

<iframe width="720" height="405" src="https://www.markslides.ai/embed/publications/11RLT1wF7QAVUwIptpP-n" title="MarkSlides Slide Viewer" frameborder="0" allow='clipboard-write; web-share' allowfullscreen></iframe>



## 1. Introdu√ß√£o √† Engenharia de Prompt (Atualizado) üöÄ

A **Engenharia de Prompt** √© uma disciplina emergente que se dedica √† arte e ci√™ncia de criar e otimizar instru√ß√µes textuais, conhecidas como "**prompts**", para orientar o comportamento de **Modelos de Linguagem Grandes (LLMs)** na gera√ß√£o de respostas precisas, relevantes e desejadas. No cen√°rio din√¢mico da intelig√™ncia artificial, a engenharia de prompt transcendeu a simples formula√ß√£o de comandos, evoluindo para uma pr√°tica sofisticada que envolve design estrat√©gico e refinamento iterativo [1]. Essa evolu√ß√£o reflete o aumento da capacidade dos LLMs de interpretar instru√ß√µes complexas e at√© mesmo de realizar racioc√≠nios com os prompts adequados.

Assim como a programa√ß√£o tradicional depende de c√≥digos bem estruturados para executar tarefas, a "programa√ß√£o" de LLMs ocorre por meio da linguagem natural, atrav√©s dos prompts. A engenharia de prompt torna-se, portanto, fundamental para desbloquear todo o potencial dessas poderosas ferramentas de IA em diversas aplica√ß√µes, desde a cria√ß√£o de conte√∫do e respostas a perguntas at√© a gera√ß√£o de c√≥digo e muito mais [2]. Prompts mal elaborados podem levar a resultados imprecisos, irrelevantes ou at√© mesmo sem sentido, desperdi√ßando recursos computacionais e dificultando o desenvolvimento de aplica√ß√µes de IA eficazes [Original Material]. A qualidade do prompt influencia diretamente a qualidade da sa√≠da, o que enfatiza a necessidade de uma abordagem sistem√°tica e informada para o design de prompts [Original Material]. √Ä medida que os LLMs se tornam mais poderosos, como o GPT-4, Claude 3 e Llama 3, sua capacidade de compreender instru√ß√µes complexas e realizar tarefas sofisticadas atrav√©s de prompts aumenta significativamente, tornando a engenharia de prompt uma habilidade ainda mais essencial [2].

Esta aula abordar√° os conceitos fundamentais e avan√ßados da engenharia de prompt, explorando as configura√ß√µes dos LLMs, t√©cnicas b√°sicas e avan√ßadas de prompting, exemplos pr√°ticos para teste em sala de aula e os recursos mais recentes nesta √°rea em constante evolu√ß√£o. üßë‚Äçüè´

## 2. Fundamentos da Engenharia de Prompt (Aprimorado) üß±

### 2.1. Configura√ß√µes da LLM (Atualizado) ‚öôÔ∏è

#### Temperatura üå°Ô∏è
A **temperatura** √© um par√¢metro crucial que controla a aleatoriedade e a criatividade da sa√≠da gerada pelo LLM [4].
*   Uma **temperatura mais baixa** (pr√≥xima de 0) torna a sa√≠da mais determin√≠stica, focada e propensa a selecionar o token seguinte mais prov√°vel. Ideal para respostas factuais ou tarefas que exigem precis√£o e consist√™ncia [5].
*   Uma **temperatura mais alta** (pr√≥xima de 1 ou acima, dependendo do modelo) introduz mais aleatoriedade, resultando em sa√≠das mais diversas, criativas e, por vezes, menos previs√≠veis. Adequada para brainstorming ou escrita criativa [5].
*   A Vellum.ai explica que a temperatura regula como um LLM pondera as probabilidades dos tokens poss√≠veis para a pr√≥xima palavra [8].
*   Diferentes modelos podem ter diferentes faixas (ex: Claude: 0.0 a 1.0) [8]. Compreender essa compensa√ß√£o √© fundamental.

**Exemplo para Teste em Sala de Aula:** üß™
Testar com Temperatura 0 e 0.7:
```text
Qual √© a capital da Fran√ßa?
```
Observe a diferen√ßa na sa√≠da.

**Exemplo para Teste em Sala de Aula:** ‚úçÔ∏è
Utilize um prompt de escrita criativa e experimente diferentes valores de temperatura (ex: 0.2, 0.8, 1.5 se permitido):
```text
Escreva uma pequena hist√≥ria sobre um gato falante.
```
Veja como a hist√≥ria varia em criatividade e coer√™ncia.

#### Tokens üî¢
**Tokens** s√£o as unidades b√°sicas de texto que os LLMs processam (palavra, parte de palavra, pontua√ß√£o) [9, 10].
*   O n√∫mero de tokens no prompt e na resposta influencia o custo e o tempo de processamento [4].
*   **Janela de contexto**: Limita o n√∫mero total de tokens que um LLM pode processar em uma intera√ß√£o [4]. (Ex: Limites de caracteres/tokens em modelos GPT [Original Material]).
*   Estimar tokens e considerar a janela de contexto √© essencial para design eficiente, especialmente para tarefas complexas. Exceder limites pode causar erros ou respostas truncadas [12].

**Exemplo para Teste em Sala de Aula:** üìä
Estimar o n√∫mero de tokens (use tokenizadores online se necess√°rio). Veja como o comprimento da resposta pode ser limitado.
```text
Explique o conceito de fotoss√≠ntese de forma simples para uma crian√ßa de 10 anos. Inclua os principais componentes envolvidos.
```

#### TopP (Amostragem de N√∫cleo) üéØ
O **TopP** (amostragem de n√∫cleo) controla a aleatoriedade selecionando de um subconjunto dos tokens mais prov√°veis [14].
*   Considera o menor conjunto de tokens cuja probabilidade cumulativa excede um limite (ex: 0.9) [4].
*   **TopP baixo** (pr√≥ximo de 0): Foca nos tokens mais prov√°veis, sa√≠das mais previs√≠veis/conservadoras.
*   **TopP alto** (pr√≥ximo de 1): Considera mais tokens, sa√≠das mais diversas/criativas [15].
*   Geralmente, Temperatura e TopP n√£o s√£o modificados simultaneamente [18]. Oferece controle sutil sobre a diversidade.

**Exemplo para Teste em Sala de Aula:** ü§î
Use um prompt com m√∫ltiplas continua√ß√µes razo√°veis e experimente TopP baixo e alto:
```text
A melhor maneira de aprender uma nova l√≠ngua √©...
```
Observe a variedade de conclus√µes geradas.

### 2.2. Prompts B√°sicos (Aprimorado) üå±

#### Prompting Zero-shot
Instruir o LLM a executar uma tarefa **sem fornecer exemplos** no prompt [19]. O modelo usa seu conhecimento pr√©-treinado [20]. LLMs modernos t√™m fortes capacidades zero-shot [21]. A efic√°cia depende da clareza das instru√ß√µes, enquadramento, contexto e formato de sa√≠da [19].

**Exemplos para Teste em Sala de Aula:** üëá

*   **Gera√ß√£o de Texto:**
    ```text
    Escreva um pequeno poema sobre o oceano.
    ```

*   **Tradu√ß√£o:**
    ```text
    Traduza 'Ol√°' para franc√™s.
    ```

*   **Sumariza√ß√£o:**
    ```text
    Resuma o seguinte texto em uma frase: 'A raposa marrom r√°pida pula sobre o c√£o pregui√ßoso para alcan√ßar o outro lado da colina.'
    ```

*   **Classifica√ß√£o:**
    ```text
    Classifique o sentimento do seguinte texto como positivo, negativo ou neutro: 'Eu realmente gostei do filme.'
    ```

#### Prompting Few-shot
Fornecer um **pequeno n√∫mero de exemplos** (demonstra√ß√µes ou "shots") dentro do prompt para guiar o LLM sobre formato, estilo e tarefa [28]. Permite aprendizado no contexto sem ajuste fino expl√≠cito [29]. Geralmente 2 a 5 exemplos [31]. O espa√ßo de r√≥tulos, distribui√ß√£o do texto e ordem dos exemplos podem influenciar [29, 28]. LLMs podem at√© gerar exemplos para prompts few-shot [28]. Melhora significativamente o desempenho onde zero-shot √© insuficiente [33].

**Exemplos para Teste em Sala de Aula:** üëá

*   **Gera√ß√£o de Texto com Estilo:** ‚úçÔ∏è
    ```text
    Escreva um tweet imitando o estilo de um autor famoso.

    Exemplo 1:
    Texto: 'Ser ou n√£o ser, eis a quest√£o.' - William Shakespeare
    Tweet: Ser ou n√£o ser, eis a quest√£o. #Shakespeare #Dilema

    Exemplo 2:
    Texto: 'Era um dia frio e brilhante de abril, e os rel√≥gios davam treze badaladas.' - George Orwell
    Tweet: Abril frio e brilhante, rel√≥gios batendo treze. O futuro √© agora? #Orwell #1984

    Novo Prompt:
    Texto: 'A √∫nica verdadeira sabedoria est√° em saber que voc√™ n√£o sabe nada.' - S√≥crates
    Tweet:
    ```

*   **Sumariza√ß√£o de Texto com Formato:** üìÑ‚û°Ô∏èüìù
    ```text
    Resuma os seguintes artigos em uma frase.

    Artigo 1: 'Estudo mostra que o exerc√≠cio melhora o humor.'
    Resumo 1: 'O exerc√≠cio est√° ligado a um melhor humor.'

    Artigo 2: 'Nova pesquisa indica uma correla√ß√£o entre sono e fun√ß√£o cognitiva.'
    Resumo 2: 'A qualidade do sono afeta as habilidades cognitivas.'

    Novo Prompt:
    Artigo: 'A empresa anunciou lucros recordes no trimestre devido ao aumento das vendas e √† redu√ß√£o de custos.'
    Resumo:
    ```


*   **Classifica√ß√£o de Texto com R√≥tulos:** üëçüëé
    ```text
    Classifique o sentimento das seguintes avalia√ß√µes como positivo ou negativo.

    Avalia√ß√£o 1: 'A comida estava deliciosa!' // Positivo
    Avalia√ß√£o 2: 'O servi√ßo foi p√©ssimo.' // Negativo

    Nova Avalia√ß√£o: 'O ambiente era agrad√°vel, mas os pre√ßos eram muito altos.' //
    ```

### 2.3. Elementos de um Prompt (Detalhado) üß©
Um prompt eficaz geralmente cont√©m [37]:

*   **Instru√ß√£o:** A tarefa espec√≠fica para o modelo. Deve ser clara, concisa e direcionada [19].
    *   **Exemplo para Teste em Sala de Aula:** Em vez de "Fale sobre o tempo", use:
        ```text
        Descreva o tempo em Londres amanh√£, incluindo temperatura, precipita√ß√£o e velocidade do vento.
        ```
*   **Contexto:** Informa√ß√µes adicionais relevantes para ajudar o modelo [19].
    *   **Exemplo para Teste em Sala de Aula:** Forne√ßa contexto antes da pergunta:
        ```text
        Contexto: A Torre Eiffel √© uma torre de treli√ßa de ferro forjado no Champ de Mars, em Paris, Fran√ßa. √â nomeada em homenagem ao engenheiro Gustave Eiffel, cuja empresa projetou e construiu a torre.

        Pergunta: Quando a Torre Eiffel foi constru√≠da?
        ```
*   **Dados de Entrada:** A pergunta ou informa√ß√£o espec√≠fica a ser processada [37].
    *   **Exemplo para Teste em Sala de Aula:** O texto a ser traduzido:
        ```text
        Traduza a seguinte frase para o espanhol: 'Obrigado pela sua ajuda.'
        ```
*   **Indicador de Sa√≠da:** Especifica o formato ou tipo de sa√≠da desejado [19].
    *   **Exemplo para Teste em Sala de Aula:**
        ```text
        Resuma o seguinte artigo em tr√™s t√≥picos: [texto do artigo aqui]
        ```

### 2.4. Dicas Gerais para Projetar Prompts (Refinado) üí°
Dicas para melhorar a qualidade das respostas [39]:

*   ‚úÖ **Comece Simples:** Inicie com prompts diretos e aumente a complexidade gradualmente.
*   üéØ **Seja Espec√≠fico e Detalhado:** Evite linguagem vaga [3].
*   üó£Ô∏è **Forne√ßa Instru√ß√µes Claras:** Use verbos de a√ß√£o, seja direto [3].
*   üîÑ **Experimente Iterativamente:** Teste diferentes formula√ß√µes, palavras-chave, contextos.
*   ‚ûï **Concentre-se no Que Voc√™ Quer:** Defina o comportamento desejado, n√£o o indesejado.
*   üöß **Use Delimitadores:** Separe partes do prompt com ```, <>, ###, etc. [Original Material].
    *   **Exemplo para Teste em Sala de Aula:**
        ```text
        ### Instru√ß√£o ###
        Traduza o texto abaixo para o espanhol:
        ### Texto ###
        Ol√°, como voc√™ est√°?
        ```
*   üé≠ **Pe√ßa ao Modelo para Adotar uma Persona:** Instrua o modelo a assumir um papel [39].
    *   **Exemplo para Teste em Sala de Aula:**
        ```text
        Voc√™ √© um assistente de ensino √∫til e entusiasmado. Explique o conceito de engenharia de prompt para um aluno de forma simples.
        ```
*   ü™ú **Especifique as Etapas Necess√°rias:** Para tarefas complexas, divida o processo [40].
*   üìè **Especifique o Comprimento Desejado:** Declare requisitos de comprimento (ex: "Resuma em no m√°ximo 100 palavras") [40].
*   üö´ **Evite Imprecis√µes:** Seja claro sobre n√∫mero de frases, estilo, etc.
*   üß† **Considere as Limita√ß√µes do Modelo:** Esteja ciente das limita√ß√µes de racioc√≠nio, conhecimento, etc.

## 3. T√©cnicas Avan√ßadas de Engenharia de Prompt üöÄüß†

### 3.1. Prompting Chain-of-Thought (CoT) (Abrangente) ü§îü™ú
O **Chain-of-Thought (CoT)** aprimora o racioc√≠nio dos LLMs guiando-os a gerar etapas intermedi√°rias antes da resposta final [41]. Imita a resolu√ß√£o de problemas humanos [42]. Eficaz para racioc√≠nio complexo (matem√°tica, senso comum, manipula√ß√£o simb√≥lica) [44]. Geralmente requer LLMs grandes (>100B par√¢metros) [43]. A capacidade de racioc√≠nio parece correlacionada com a escala do modelo [46]. CoT aproveita a capacidade inerente de modelos maiores para racioc√≠nio em v√°rias etapas [41].

#### CoT Zero-shot
Adicionar uma frase simples como "**Vamos pensar passo a passo.**" ao final do prompt original [49]. Pode provocar racioc√≠nio sem exemplos expl√≠citos [21]. Sugere habilidades latentes de racioc√≠nio ativadas com prompting m√≠nimo [49, 50].

**Exemplo para Teste em Sala de Aula:** üî¢

*   **Prompt sem CoT:**
    ```text
    Se Jo√£o tem 5 peras, come 2 e compra mais 5, depois d√° 3 para seu amigo, quantas peras ele tem?
    ```
*   **Prompt com CoT Zero-shot:**
    ```text
    Se Jo√£o tem 5 peras, come 2 e compra mais 5, depois d√° 3 para seu amigo, quantas peras ele tem? Vamos pensar passo a passo.
    ```

Compare as respostas.

#### CoT Few-shot
CoT FS Fornece exemplos no prompt que demonstram o processo de racioc√≠nio passo a passo, incluindo etapas intermedi√°rias e resposta final [45]. Serve como modelo para o LLM seguir [26]. Aproveita habilidades de reconhecimento de padr√µes para resolu√ß√£o mais sofisticada [43].

**Exemplo para Teste em Sala de Aula:** üß©

```text
Pergunta: H√° 15 √°rvores no bosque. Os trabalhadores do bosque plantar√£o √°rvores no bosque hoje. Depois que terminarem, haver√° 21 √°rvores. Quantas √°rvores os trabalhadores do bosque plantaram hoje?
Resposta: Havia 15 √°rvores originalmente. Ent√£o, havia 21 √°rvores depois que mais algumas foram plantadas. Portanto, devem ter sido 21 - 15 = 6. A resposta √© 6.

Pergunta: Se houver 3 carros no estacionamento e mais 2 carros chegarem, quantos carros haver√° no estacionamento?
Resposta: Havia originalmente 3 carros. Mais 2 carros chegaram. 3 + 2 = 5. A resposta √© 5.

Pergunta: Leah tinha 32 chocolates e sua irm√£ tinha 42. Se elas comeram 35, quantos peda√ßos restaram no total?
Resposta: Originalmente, Leah tinha 32 chocolates. Sua irm√£ tinha 42. Ent√£o, no total, elas tinham 32 + 42 = 74. Depois de comer 35, restaram 74 - 35 = 39. A resposta √© 39.

Pergunta: Jason tinha 20 pirulitos. Ele deu alguns pirulitos para Denny. Agora Jason tem 12 pirulitos. Quantos pirulitos Jason deu para Denny?
Resposta:
```

### 3.2. Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) (Nova Se√ß√£o) üìöüîç
A **Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)** combina recupera√ß√£o de informa√ß√µes com gera√ß√£o de texto para aprimorar a precis√£o e o conhecimento dos LLMs, especialmente para tarefas intensivas em conhecimento [51]. Aborda limita√ß√µes como lacunas de conhecimento, informa√ß√µes desatualizadas e alucina√ß√µes [52].
*   **Fluxo B√°sico:** Consulta do usu√°rio -> Modelo de recupera√ß√£o busca documentos relevantes -> Informa√ß√µes recuperadas s√£o incorporadas ao prompt com a consulta original -> Prompt aumentado √© alimentado no LLM -> LLM gera resposta mais precisa usando as informa√ß√µes recuperadas [52].
*   Permite ao LLM acessar conhecimento mais amplo e atualizado [55], reduzindo erros factuais [52].

**Exemplos para Teste em Sala de Aula e Casos de Uso:** üåç

*   **Q&A sobre Documentos Personalizados:** Utilize documentos para formular prompts que usariam RAG (com ferramenta adequada) para responder perguntas baseadas nesses documentos [52].
*   **Assistentes Virtuais Atualizados:** Como RAG pode fornecer informa√ß√µes atuais sobre eventos, clima, not√≠cias [53].
*   **Cria√ß√£o de Conte√∫do Factual:** Como RAG auxilia na gera√ß√£o de artigos/relat√≥rios com fatos e n√∫meros relevantes [52].

### 3.3. React (Reason and Act) (Nova Se√ß√£o) ü§ñ‚û°Ô∏èüåç
O framework **ReAct (Reason + Act)** permite que LLMs gerem rastros de **racioc√≠nio (Reason)** e **a√ß√µes (Act)** espec√≠ficas da tarefa de forma intercalada para resolver tarefas complexas que podem exigir intera√ß√£o com fontes externas [59].
*   **Racioc√≠nio:** Ajuda o modelo a planejar e criar estrat√©gias.
*   **A√ß√£o:** Permite interagir com ambientes externos (mecanismos de busca, APIs, bancos de dados) para coletar informa√ß√µes [60].
*   **Ciclo T√≠pico:** Raciocinar sobre estado/info necess√°ria -> Tomar A√ß√£o (ex: busca) -> Observar resultado -> Continuar ciclo com mais racioc√≠nio/a√ß√µes baseado nas observa√ß√µes -> Tarefa conclu√≠da [59].
*   Permite tarefas mais complexas e din√¢micas, integrando racioc√≠nio com intera√ß√£o externa, resultando em respostas mais fundamentadas [60].

**Exemplos para Teste em Sala de Aula e Casos de Uso:** üõ†Ô∏è

*   **Exemplo Q&A com Busca Externa:** Exemplo de pergunta que exige info externa (ex: "Qual hotel hospeda o show 'Myst√®re' do Cirque du Soleil e quantos quartos ele tem?"). 
    ```text
    Pergunta: Qual hotel hospeda o show 'Myst√®re' do Cirque du Soleil e quantos quartos ele tem?

    Pensamento 1: Preciso encontrar o hotel que hospeda 'Myst√®re' e depois o n√∫mero de quartos desse hotel. Primeiro, buscarei por "hotel show Myst√®re Cirque du Soleil".
    A√ß√£o 1: search[hotel show Myst√®re Cirque du Soleil]
    Observa√ß√£o 1: A busca retorna que o show 'Myst√®re' est√° no hotel Treasure Island (TI) em Las Vegas.
    Pensamento 2: Agora sei o hotel (Treasure Island). Preciso encontrar o n√∫mero de quartos. Buscarei por "n√∫mero de quartos Treasure Island Las Vegas".
    A√ß√£o 2: search[n√∫mero de quartos Treasure Island Las Vegas]
    Observa√ß√£o 2: A busca retorna que o Treasure Island Hotel & Casino tem 2.884 quartos.
    Pensamento 3: Encontrei as duas informa√ß√µes. O hotel √© Treasure Island e tem 2.884 quartos. Posso formular a resposta final.
    A√ß√£o 3: finish[O show 'Myst√®re' do Cirque du Soleil est√° hospedado no hotel Treasure Island (TI) em Las Vegas, que possui 2.884 quartos.]
    ```

### 3.4. Outras T√©cnicas Avan√ßadas (Breve Vis√£o Geral) ‚ú®

*   **Prompting Tree-of-Thoughts (ToT):** Explora m√∫ltiplos caminhos de racioc√≠nio, considera diferentes possibilidades e retrocede se necess√°rio. √ötil para problemas complexos sem solu√ß√£o √≥bvia [64]. üå≥
*   **Autoconsist√™ncia (Self-Consistency):** Gera m√∫ltiplos caminhos de racioc√≠nio diversos para o mesmo prompt usando CoT e seleciona a resposta mais consistente (mais frequente) [26]. üîÑ

## Exerc√≠cios

Para consolidar os conceitos apresentados, aqui estaÃÉo alguns exerciÃÅcios praÃÅticos para voceÃÇ aplicar as teÃÅcnicas baÃÅsicas da engenharia de prompts. 

Para cada exerc√≠cio anote o Modelo utilizado, **prompt inicial** e a **resposta obtida**, **o prompt final** (que lhe agradou) e **a resposta obtida**. Segue modelo

**Exerc√≠cio 1:**

Modelo: **llama-3.3-70b-specdec**

**Prompt Inicial:**
> O C√©u √©

**Sa√≠da inicial:**
> Azul

**Prompt Final:**
> O C√©u √©

**Sa√≠da final:**
> Azul

---
1. Crie um prompt simples pedindo ao modelo para escrever uma carta de recomendacÃßaÃÉo sem fornecer nenhum contexto adicional. Depois, revise o prompt adicionando detalhes sobre o destinataÃÅrio e o propoÃÅsito da carta. Como o contexto influenciou a qualidade da resposta?

O contexto melhorou muito a resposta, sem o contexto ele criou uma carta de recomenda√ß√£o muito boa, mas para ser usada como base, similar a um curriculum em branco. Mas adicionando o contexto o a ferramenta criou uma carta de recomenda√ß√£o sensacional, adicionando todos as especifica√ß√µes do funcion√°rio em quest√£o, e mesmo sem deixar claro com exatid√£o qual a fun√ß√£o √† qual ele se candidatava o modelo fez uma an√°lise e adicionou isso a carta.

2. Defina uma persona para um assistente virtual que auxilia clientes de uma livraria. Crie um prompt que utilize essa persona para responder clientes e indicar livros. Avalie como a definicÃßaÃÉo de persona impacta a resposta do modelo.

A defini√ß√£o da persona impacta muito nas diretrizes de como ela responde, deixando as respostas muito mais especificas e exatas sobre o assunto em quest√£o. O modelo trabalha respondendo com muito entusiasmo e com assertividade  de conhecimento do assunto.

3. Escreva um prompt vago pedindo ao modelo para descrever um cenaÃÅrio futurista, sem dar detalhes. Depois, reescreva o prompt com instrucÃßoÃÉes claras e especiÃÅficas sobre o tipo de cenaÃÅrio e detalhes a serem incluiÃÅdos. Avalie a importaÃÇncia da clareza nas instrucÃßoÃÉes.

O modelo descreve muito o que √© pedido, com um n√≠vel imaginativo muito interessante. Mas quando o contexto e detalhes do que se deseja que ele imagine √© adicionado o modelo trabalha muito melhor e imagina um cen√°rio muito interessante que seria de se pensar colocar num modelo que gere v√≠deo, porque acredito que fique bem legal.

4. Desenvolva um prompt inicial para gerar uma breve biografia de uma figura histoÃÅrica a ser definida por voc√™. Analise a resposta e refine o prompt adicionando detalhes, informa√ß√µes adicionais e ajustando as instrucÃßoÃÉes. Realize vaÃÅrias iteracÃßoÃÉes e observe como cada refinamento melhora a precisaÃÉo da resposta.
5. Desenvolva um prompt personalizado para um posto de gasolina. Use todas as teÃÅcnicas discutidas neste capiÃÅtulo para otimizar o prompt. Avalie a eficaÃÅcia do prompt baseado na resposta do modelo e facÃßa os ajustes necessaÃÅrios. Utilize o ChatGPT ou outro servi√ßo √† sua escolha para auxiliar na gera√ß√£o de um prompt interativo.
6. Escreva dois prompts sobre o mesmo tema, mas com diferentes entonacÃßoÃÉes: um formal e outro casual. Utilize a escala de entonacÃßaÃÉo de 1 a 10.
7. Crie dois prompts para gerar textos com diferentes sentimentos sobre o mesmo assunto. Utilize a escala de sentimento de 1 a 10.
8. Crie treÃÇs prompts sobre o mesmo tema, cada um utilizando uma perspectiva diferente: primeira, segunda e terceira pessoa. Utilize a escala de perspectiva de 1 a 3.
9. Escreva dois prompts que descrevam a mesma cena, mas com diferentes niÃÅveis de detalhe. Utilize a escala de niÃÅvel de detalhe de 1 a 10.
## Conclus√£o ‚úÖüéâ

A **engenharia de prompt** √© crucial para usar LLMs eficazmente. A capacidade de criar e refinar prompts influencia diretamente a qualidade da sa√≠da da IA. Compreender configura√ß√µes, dominar t√©cnicas b√°sicas e explorar metodologias avan√ßadas (CoT, RAG, ReAct) capacita os usu√°rios. Os exemplos e exerc√≠cios pr√°ticos s√£o um ponto de partida valioso. Com o avan√ßo da IA, a engenharia de prompt permanecer√° essencial. A explora√ß√£o cont√≠nua dos recursos atualizados garantir√° que profissionais e estudantes estejam na vanguarda desta √°rea din√¢mica.

## Refer√™ncias Citadas üìÑ

1.  Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/
2.  What is Prompt Engineering? Trend in 2024, acessado em mar√ßo 25, 2025, https://dataengineeracademy.com/blog/what-is-prompt-engineering-trend-in-2024/
3.  What is Prompt Engineering? Step-by-Step Guide + Examples - Coralogix, acessado em mar√ßo 25, 2025, https://coralogix.com/ai-blog/ultimate-guide-to-prompt-engineering-examples/
4.  LLM Parameters: Tuning & Optimization for Better Performance - Data Science Dojo, acessado em mar√ßo 25, 2025, https://datasciencedojo.com/blog/tuning-optimizing-llm-parameters/
5.  Decoding LLM Parameters, Part 1: Temperature - DZone, acessado em mar√ßo 25, 2025, https://dzone.com/articles/decoding-llm-parameters-temperature
6.  What is LLM Temperature | Iguazio, acessado em mar√ßo 25, 2025, https://www.iguazio.com/glossary/llm-temperature/
7.  How to Configure LLM Temperature - ClickUp, acessado em mar√ßo 25, 2025, https://clickup.com/blog/llm-temperature/
8.  LLM Temperature: How It Works and When You Should Use It - Vellum AI, acessado em mar√ßo 25, 2025, https://www.vellum.ai/llm-parameters/temperature
9.  Anatomy of an LLM: Tokens, Weights and Parameters | Webopedia, acessado em mar√ßo 25, 2025, https://www.webopedia.com/technology/llm-tokens-weights-parameters/
10. Differnce between Token , Weight and Parameter in a LLM - DeepLearning.AI, acessado em mar√ßo 25, 2025, https://community.deeplearning.ai/t/differnce-between-token-weight-and-parameter-in-a-llm/376200
11. Understanding LLM Parameters: Inside the Engine of LLMs - ProjectPro, acessado em mar√ßo 25, 2025, https://www.projectpro.io/article/llm-parameters/1029
12. LLMs, Tokens, and Model Parameters Explained in Plain English | by Dana Prata - Medium, acessado em mar√ßo 25, 2025, https://medium.com/@danaprata/llms-tokens-and-model-parameters-explained-in-plain-english-90de354a76e1
13. Understanding Tokens and Parameters in Model Training: A Deep Dive - Functionize, acessado em mar√ßo 25, 2025, https://www.functionize.com/blog/understanding-tokens-and-parameters-in-model-training
14. How to Use the Top_P parameter? - Vellum AI, acessado em mar√ßo 25, 2025, https://www.vellum.ai/llm-parameters/top-p
15. LLM Parameters Explained: A Practical Guide with Examples for OpenAI API in Python, acessado em mar√ßo 25, 2025, https://learnprompting.org/blog/llm-parameters
16. Mastering LLM Parameters: A Deep Dive into Temperature, Top-K, and Top-P | In Plain English, acessado em mar√ßo 25, 2025, https://plainenglish.io/blog/mastering-llm-parameters-a-deep-dive-into-temperature-top-k-and-top-p
17. Complete Guide to Prompt Engineering with Temperature and Top-p, acessado em mar√ßo 25, 2025, https://promptengineering.org/prompt-engineering-with-temperature-and-top-p/
18. How to Tune LLM Parameters for Top Performance: Understanding Temperature, Top K, and Top P | phData, acessado em mar√ßo 25, 2025, https://www.phdata.io/blog/how-to-tune-llm-parameters-for-top-performance-understanding-temperature-top-k-and-top-p/
19. Zero-Shot Prompting: Examples, Theory, Use Cases - DataCamp, acessado em mar√ßo 25, 2025, https://www.datacamp.com/tutorial/zero-shot-prompting
20. Zero-Shot Prompting - Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/techniques/zeroshot
21. Prompt-Engineering-Guide/guides/prompts-advanced-usage.md at main - GitHub, acessado em mar√ßo 25, 2025, https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-advanced-usage.md
22. Zero-Shot vs. Few-Shot Prompting: Key Differences - Shelf.io, acessado em mar√ßo 25, 2025, https://shelf.io/blog/zero-shot-and-few-shot-prompting/
23. How does zero-shot learning apply to text generation? - Milvus, acessado em mar√ßo 25, 2025, https://milvus.io/ai-quick-reference/how-does-zeroshot-learning-apply-to-text-generation
24. What is Zero-Shot Prompting? Examples & Applications - Digital Adoption, acessado em mar√ßo 25, 2025, https://www.digital-adoption.com/zero-shot-prompting/
25. What is Zero-shot prompting and One-shot prompting? - Automation Anywhere | Community, acessado em mar√ßo 25, 2025, https://community.automationanywhere.com/developers-forum-36/what-is-zero-shot-prompting-and-one-shot-prompting-86895
26. Prompt Engineering: Advanced Techniques - MLQ.ai, acessado em mar√ßo 25, 2025, https://blog.mlq.ai/prompt-engineering-advanced-techniques/
27. Shot-Based Prompting: Zero-Shot, One-Shot, and Few-Shot Prompting, acessado em mar√ßo 25, 2025, https://learnprompting.org/docs/basics/few_shot
28. The Few Shot Prompting Guide - PromptHub, acessado em mar√ßo 25, 2025, https://www.prompthub.us/blog/the-few-shot-prompting-guide
29. Few-Shot Prompting - Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/techniques/fewshot
30. Provide examples (few-shot prompting) - Amazon Nova - AWS Documentation, acessado em mar√ßo 25, 2025, https://docs.aws.amazon.com/nova/latest/userguide/prompting-examples.html
31. Comprehensive Guide to Few-Shot Prompting Using Llama 3 | by Novita AI - Medium, acessado em mar√ßo 25, 2025, https://medium.com/@marketing_novita.ai/comprehensive-guide-to-few-shot-prompting-using-llama-3-d574c07b617c
32. Best Prompts for Asking a Summary: A Guide to Effective AI Summarization - PromptLayer, acessado em mar√ßo 25, 2025, https://blog.promptlayer.com/best-prompts-for-asking-a-summary-a-guide-to-effective-ai-summarization/
33. What is few shot prompting? - IBM, acessado em mar√ßo 25, 2025, https://www.ibm.com/think/topics/few-shot-prompting
34. Few-Shot Sentiment Classification with LLMs - Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/prompts/classification/sentiment-fewshot
35. Dynamic Few-Shot Prompting: Overcoming Context Limit for ChatGPT Text Classification | by Iryna Kondrashchenko | Medium, acessado em mar√ßo 25, 2025, https://medium.com/@iryna230520/dynamic-few-shot-prompting-overcoming-context-limit-for-chatgpt-text-classification-2f70c3bd86f9
36. Few-Shot Prompting: Examples, Theory, Use Cases - DataCamp, acessado em mar√ßo 25, 2025, https://www.datacamp.com/tutorial/few-shot-prompting
37. Prompt Engineering - Adnan Writes - Medium, acessado em mar√ßo 25, 2025, https://adnanwritess.medium.com/prompt-engineering-940901b35b1a
38. Elements of a Prompt - Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/introduction/elements
39. Prompt Engineering Guidelines - What's deepset AI Platform?, acessado em mar√ßo 25, 2025, https://docs.cloud.deepset.ai/docs/prompt-engineering-guidelines
40. Prompt engineering - OpenAI API, acessado em mar√ßo 25, 2025, https://platform.openai.com/docs/guides/prompt-engineering
41. Chain-of-Thought Prompting | Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/techniques/cot
42. 6 advanced AI prompt engineering techniques for better outputs - Outshift | Cisco, acessado em mar√ßo 25, 2025, https://outshift.cisco.com/blog/advanced-ai-prompt-engineering-techniques
43. Chain of Thought Prompting Guide - PromptHub, acessado em mar√ßo 25, 2025, https://www.prompthub.us/blog/chain-of-thought-prompting-guide
44. Advanced Prompt Engineering Techniques - Mercity AI, acessado em mar√ßo 25, 2025, https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques
45. Chain-of-Thought Prompting, acessado em mar√ßo 25, 2025, https://learnprompting.org/docs/intermediate/chain_of_thought
46. Chain of Thought Prompting (CoT): Everything you need to know - Vellum AI, acessado em mar√ßo 25, 2025, https://www.vellum.ai/blog/chain-of-thought-prompting-cot-everything-you-need-to-know
47. Few shot Prompting and Chain of Thought Prompting | by Mahesh Kumar SG | Medium, acessado em mar√ßo 25, 2025, https://medium.com/@maheshkumarsg1/few-shot-prompting-and-chain-of-thought-prompting-462201ab60ff
48. Zero-Shot, Few Shot, and Chain-of-thought Prompt | In Plain English, acessado em mar√ßo 25, 2025, https://plainenglish.io/blog/zero-shot-few-shot-and-chain-of-thought-prompt
49. Zero-Shot CoT Prompting: Improving AI with Step-by-Step Reasoning, acessado em mar√ßo 25, 2025, https://learnprompting.org/docs/intermediate/zero_shot_cot
50. Zero Shot Chain of Thought - Learn Prompting, acessado em mar√ßo 25, 2025, https://learnprompting.org/de/docs/intermediate/zero_shot_cot
51. Top 10 RAG Use Cases and 17 Essential Tools for Implementation - ChatBees, acessado em mar√ßo 25, 2025, https://www.chatbees.ai/blog/rag-use-cases
52. 7 Practical Applications of RAG Models and Their Impact on Society - Hyperight, acessado em mar√ßo 25, 2025, https://hyperight.com/7-practical-applications-of-rag-models-and-their-impact-on-society/
53. 10 Real-World Examples of Retrieval Augmented Generation - Signity Software Solutions, acessado em mar√ßo 25, 2025, https://www.signitysolutions.com/blog/real-world-examples-of-retrieval-augmented-generation
54. Top Use Cases of Retrieval-Augmented Generation (RAG) in AI - Glean, acessado em mar√ßo 25, 2025, https://www.glean.com/blog/retrieval-augmented-generation-use-cases
55. 7 examples of retrieval-augmented generation (RAG) - Merge, acessado em mar√ßo 25, 2025, https://www.merge.dev/blog/rag-examples
56. DigitalOcean Launches Advanced Generative AI Platform - Stock Titan, acessado em mar√ßo 25, 2025, https://www.stocktitan.net/news/DOCN/digital-ocean-launches-advanced-generative-ai-r8bdiiael2nj.html
57. DigitalOcean Launches Advanced Generative AI Platform, acessado em mar√ßo 25, 2025, https://investors.digitalocean.com/news/news-details/2025/DigitalOcean-Launches-Advanced-Generative-AI-Platform/default.aspx
58. Introducing the GenAI Platform: Simplifying AI Development for All - DigitalOcean, acessado em mar√ßo 25, 2025, https://www.digitalocean.com/blog/introducing-generative-ai-platform
59. ReAct: Integrating Reasoning and Acting with Retrieval-Augmented Generation (RAG, acessado em mar√ßo 25, 2025, https://bluetickconsultants.medium.com/react-integrating-reasoning-and-acting-with-retrieval-augmented-generation-rag-a6c2e869f763
60. ReAct prompting in LLM : Redefining AI with Synergized Reasoning and Acting - Medium, acessado em mar√ßo 25, 2025, https://medium.com/@sahin.samia/react-prompting-in-llm-redefining-ai-with-synergized-reasoning-and-acting-c19640fa6b73
61. Implement ReAct Prompting for Better AI Decision-Making, acessado em mar√ßo 25, 2025, https://relevanceai.com/prompt-engineering/implement-react-prompting-for-better-ai-decision-making
62. Reason and Act (ReAct) prompting - Hyperskill, acessado em mar√ßo 25, 2025, https://hyperskill.org/learn/step/45335
63. ReAct Systems: Enhancing LLMs with Reasoning and Action - Learn Prompting, acessado em mar√ßo 25, 2025, https://learnprompting.org/docs/agents/react
64. 6 Mind-Bending Prompt Engineering Techniques in 2024 That Will Make You an AI Whisperer | by Abhinav Bhaskar | Medium, acessado em mar√ßo 25, 2025, https://medium.com/@animagun/mastering-the-art-of-prompt-engineering-advanced-techniques-for-ai-language-models-f40c56636150
65. Prompting Techniques - Prompt Engineering Guide, acessado em mar√ßo 25, 2025, https://www.promptingguide.ai/techniques
66. Azure OpenAI Service API version lifecycle - Learn Microsoft, acessado em mar√ßo 25, 2025, https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation
67. What's new in Azure OpenAI Service? - Learn Microsoft, acessado em mar√ßo 25, 2025, https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new
68. Azure OpenAI Service models - Learn Microsoft, acessado em mar√ßo 25, 2025, https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models
69. 10 Best Online Prompt Engineering Courses [Free & Paid] with Certificates, acessado em mar√ßo 25, 2025, https://learnprompting.org/blog/prompt_engineering_courses
70. Prompt Engineering for ChatGPT - Coursera, acessado em mar√ßo 25, 2025, https://www.coursera.org/learn/prompt-engineering
71. ChatGPT Prompt Engineering for Developers - DeepLearning.AI, acessado em mar√ßo 25, 2025, https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
72. Releases ¬∑ ollama/ollama - GitHub, acessado em mar√ßo 25, 2025, https://github.com/ollama/ollama/releases
73. Blog ¬∑ Ollama, acessado em mar√ßo 25, 2025, https://ollama.com/blog